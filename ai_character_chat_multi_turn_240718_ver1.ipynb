{
 "cells": [
  {
   "cell_type": "code",
   "id": "86bcec4e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "import os"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535a53dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T11:03:41.985903Z",
     "start_time": "2024-07-18T11:03:41.950947Z"
    }
   },
   "source": [
    "# 24.07.10 test\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\",\"\").strip(),\n",
    "    api_key        = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version    = os.getenv(\"OPENAI_API_VERSION\")\n",
    ")\n",
    "\n",
    "deployment_name = os.getenv('DEPLOYMENT_NAME') # gpt-4o"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d645a53b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T11:03:42.302222Z",
     "start_time": "2024-07-18T11:03:42.295648Z"
    }
   },
   "source": [
    "# search ai에 필요한 정보 선언\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\",\"\").strip()\n",
    "search_endpoint = os.getenv('AZURE_AI_SEARCH_ENDPOINT')\n",
    "search_key = os.getenv(\"AZURE_AI_SEARCH_API_KEY\")\n",
    "search_index = os.getenv(\"AZURE_AI_SEARCH_INDEX\")\n",
    "embedding_model_name = \"text-embedding-ada-002\"\n",
    "\n",
    "print(endpoint)\n",
    "print(search_endpoint)\n",
    "print(search_key)\n",
    "print(search_index)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4623870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T11:04:30.977554Z",
     "start_time": "2024-07-18T11:04:30.907270Z"
    }
   },
   "source": [
    "# Multi-turn 구현\n",
    "\n",
    "class AICharacterChat:\n",
    "    def __init__(self, deployment_name, search_endpoint, search_index, search_key):\n",
    "        self.deployment_name = deployment_name\n",
    "        self.search_endpoint = search_endpoint\n",
    "        self.search_index = search_index\n",
    "        self.search_key = search_key\n",
    "        self.messages = []\n",
    "\n",
    "    def start_conversation(self, book_name, character):\n",
    "        # 시스템 메시지에서 특정 구문이 날라올 경우, gpt가 알고 있는 내용으로 답변해줘.\n",
    "        system_msg = f\"당신의 유일한 역할은 {book_name} 책의 {character} 역할이다. {character} 역할이라고 생각하고 질문에 답변해.\"\n",
    "        self.messages.append({\"role\": \"system\", \"content\": system_msg})\n",
    "\n",
    "    def get_ai_character_chat_fast(self, user_query, temperature=0):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_query})\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=self.deployment_name,\n",
    "            messages=self.messages,\n",
    "            max_tokens=300,\n",
    "            temperature=temperature,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=False,\n",
    "            extra_body={\n",
    "                \"data_sources\": [{\n",
    "                    \"type\": \"azure_search\",\n",
    "                    \"parameters\": {\n",
    "                        \"endpoint\": f\"{self.search_endpoint}\",\n",
    "                        \"index_name\": f\"{self.search_index}\",\n",
    "                        \"semantic_configuration\": f\"{self.search_index}-semantic-configuration\",\n",
    "                        \"query_type\": \"vector_semantic_hybrid\",\n",
    "                        \"in_scope\": True,\n",
    "                        \"role_information\": self.messages[0][\"content\"],\n",
    "                        \"strictness\": 1, # default : 3 / 값을 낮추면 더 빠른 응답을 얻을 수 있지만, 정보의 정확성이 떨어질 수 있음\n",
    "                        \"top_n_documents\": 1, # default : 5 / 검색 결과 개수 설정, '3'\n",
    "                        \"authentication\": {\n",
    "                            \"type\": \"api_key\",\n",
    "                            \"key\": f\"{self.search_key}\"\n",
    "                        },\n",
    "                        \"embedding_dependency\": {\n",
    "                            \"type\": \"deployment_name\",\n",
    "                            \"deployment_name\": \"text-embedding-ada-002\"\n",
    "                        }\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        response_content = response.choices[0].message.content\n",
    "        check_resp_list = ['다른 질문', '다른 질문', '이 질문은 내가 답변할 수 있는 범위를', '요청하신 정보는 제공된',\n",
    "                           '제공된 문서에서', '대화에서 벗어난', '답할 수 없어']\n",
    "\n",
    "        if any(check_resp in response_content for check_resp in check_resp_list):\n",
    "            print('[INFO] Not use vector_semantic_hybrid...')\n",
    "            print('Error response_content: ', response_content)\n",
    "            print('')\n",
    "            # 검색 결과가 없을 경우 유연한 답변 생성\n",
    "            # mod_user_query = '{character}의 입장에서 {user_query}를 대답해줘.'\n",
    "            response_content = self.generate_fallback_response()\n",
    "        \n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response_content})\n",
    "        \n",
    "        return response_content\n",
    "    \n",
    "    def generate_fallback_response(self):\n",
    "        \n",
    "        # 기존 대화와 맥락을 바탕으로 유연한 답변을 생성\n",
    "        fallback_response = client.chat.completions.create(\n",
    "            model=self.deployment_name,\n",
    "            messages=self.messages,\n",
    "            max_tokens=300,\n",
    "            temperature=0.7,  # 창의적 답변을 위해 온도 조절\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=False\n",
    "        )\n",
    "        return fallback_response.choices[0].message.content"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2dc7603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T11:04:05.998176Z",
     "start_time": "2024-07-18T11:03:44.028580Z"
    }
   },
   "source": [
    "# 사용 예시\n",
    "chatbot_test = AICharacterChat(deployment_name, search_endpoint, search_index, search_key)\n",
    "chatbot_test.start_conversation(book_name=\"어린 왕자\", character=\"여우\")\n",
    "\n",
    "# 첫 번째 질문\n",
    "response1 = chatbot_test.get_ai_character_chat_fast(\"어린 왕자를 어떻게 생각해?\")\n",
    "print(response1)\n",
    "\n",
    "print('#' * 30)\n",
    "\n",
    "# 두 번째 질문\n",
    "response2 = chatbot_test.get_ai_character_chat_fast(\"너가 지금 먹고 싶은 음식은 뭐야?\")\n",
    "print(response2)\n",
    "\n",
    "print('#' * 30)\n",
    "\n",
    "response3 = chatbot_test.get_ai_character_chat_fast(\"어린왕자와 대화하는 거 말고 너가 지금 먹고 싶은 음식은 뭐야?\")\n",
    "print(response3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce000e",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70b4c2",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
